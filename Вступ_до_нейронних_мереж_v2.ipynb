{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastasiia-vsk/ML_course/blob/main/%D0%92%D1%81%D1%82%D1%83%D0%BF_%D0%B4%D0%BE_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B8%D1%85_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ],
      "metadata": {
        "id": "lbLHTNfSclli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ],
      "metadata": {
        "id": "GtOYB-RHfc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_tensor = torch.from_numpy(inputs)\n",
        "targets_tensor = torch.from_numpy(targets)\n",
        "\n",
        "print(\"Inputs Tensor:\")\n",
        "print(inputs_tensor)\n",
        "\n",
        "print(\"\\nTargets Tensor:\")\n",
        "print(targets_tensor)"
      ],
      "metadata": {
        "id": "KjoeaDrk6fO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb02d65-f707-4ea7-baa3-5323e3236873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs Tensor:\n",
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "\n",
            "Targets Tensor:\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ],
      "metadata": {
        "id": "iKzbJKfOgGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)"
      ],
      "metadata": {
        "id": "aXhKw6Tdj1-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288bfbbd-962d-483b-f2d3-cb76c1615c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d42542998b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(1, 3, dtype=torch.float32)\n",
        "b = torch.randn(1, dtype=torch.float32)\n",
        "\n",
        "print(\"w =\", w)\n",
        "print(\"b =\", b)"
      ],
      "metadata": {
        "id": "eApcB7eb6h9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d955ee54-2ec6-481e-fdb1-4c2d882482e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = tensor([[0.6614, 0.2669, 0.0617]])\n",
            "b = tensor([0.6213])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ],
      "metadata": {
        "id": "nYGxNGTaf5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def model(x):\n",
        "#     return 1 / (1 + torch.exp(-(x @ w + b)))"
      ],
      "metadata": {
        "id": "pSz2j4Fh6jBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x, w, b):\n",
        "    return 1/(1 + torch.exp(-(x @ w.t() + b)))"
      ],
      "metadata": {
        "id": "XvlS52SI7E-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs_tensor, w,b)\n",
        "\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIY5Zbw6E6DW",
        "outputId": "b19c2239-f79f-4e0b-820a-9f044e127558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Так, передбачення трохи підозрілі — всі значення рівні 1.0, тобто модель \"впевнена\", що у всіх випадках буде позитивний результат (яблук більше 80). Це виглядає неприродно, бо в реальних даних навряд чи всі приклади мають однакову відповідь.*\n",
        "\n",
        "*Швидше за все, це пов’язано з тим, що значення x @ w + b виходять дуже великими, і сигмоїда перетворює їх у значення, близькі до 1. Імовірна причина — ваги w і b мають завеликі значення після ініціалізації. Можна спробувати змінити масштаб випадкових ваг (зробити їх меншими, аналогічно до того, як робили це в лекції)*"
      ],
      "metadata": {
        "id": "fc4WejQwHGv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ],
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels):\n",
        "    epsilon = 1e-5\n",
        "    predicted_probs = torch.clamp(predicted_probs, epsilon, 1 - epsilon)\n",
        "\n",
        "    loss = - (true_labels * torch.log(predicted_probs) + (1 - true_labels) * torch.log(1 - predicted_probs))\n",
        "\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "1bWlovvx6kZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ],
      "metadata": {
        "id": "ZFKpQxdHi1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w.requires_grad_()\n",
        "b.requires_grad_()"
      ],
      "metadata": {
        "id": "YAbXUNSJ6mCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a9177e-8dac-4b9c-d9d1-6fc35f3998a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6213], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs_tensor, w, b)"
      ],
      "metadata": {
        "id": "PSRofD3xffmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(preds, targets_tensor)"
      ],
      "metadata": {
        "id": "5bMmLBoTfjqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "kLi0Oy52fq8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Градієнти w:\")\n",
        "print(w.grad)\n",
        "\n",
        "print(\"\\nГрадієнт b:\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csozvhtDftT6",
        "outputId": "2c990849-7cf1-4c8b-fc0e-e4c13cd6bdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Градієнти w:\n",
            "tensor([[0., 0., 0.]])\n",
            "\n",
            "Градієнт b:\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ],
      "metadata": {
        "id": "nDN1t1RujQsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ],
      "metadata": {
        "id": "rOPSQyttpVjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# w.requires_grad_()\n",
        "# b.requires_grad_()"
      ],
      "metadata": {
        "id": "IAzwuR-FiITy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ],
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs_tensor, w, b)\n",
        "\n",
        "loss = binary_cross_entropy(preds, targets_tensor)\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "-JwXiSpX6orh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Передбачення:\")\n",
        "print(preds)\n",
        "\n",
        "print(\"\\nВтрати:\")\n",
        "print(loss.item())\n",
        "\n",
        "print(\"\\nГрадієнти w:\")\n",
        "print(w.grad)\n",
        "\n",
        "print(\"\\nГрадієнт b:\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOamWRzXhPLB",
        "outputId": "22305894-30a0-44b8-ae4c-1c24335ee9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Передбачення:\n",
            "tensor([[0.5174],\n",
            "        [0.5220],\n",
            "        [0.5244],\n",
            "        [0.5204],\n",
            "        [0.5190]], grad_fn=<MulBackward0>)\n",
            "\n",
            "Втрати:\n",
            "0.6829456686973572\n",
            "\n",
            "Градієнти w:\n",
            "tensor([[ -5.4417, -18.9853, -10.0682]])\n",
            "\n",
            "Градієнт b:\n",
            "tensor([-0.0794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Тепер усе виглядає адекватно. Передбачення близькі до 0.5, бо модель ще не \"впевнена\", втрати — високі, бо вона ще не навчилась добре передбачати, а градієнти нормальні, тобто модель готова оновлювати ваги. Все це — добрий старт для навчання!*"
      ],
      "metadata": {
        "id": "V7oYcOGkimUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ],
      "metadata": {
        "id": "RCdi44IT334o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    preds = model(inputs_tensor, w, b)\n",
        "\n",
        "    loss = binary_cross_entropy(preds, targets_tensor)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch + 1}: Loss = {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "mObHPyE06qsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47da41ad-41ce-4d22-e727-36bdf22953f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100: Loss = 0.5626\n",
            "Epoch 200: Loss = 0.5071\n",
            "Epoch 300: Loss = 0.4650\n",
            "Epoch 400: Loss = 0.4327\n",
            "Epoch 500: Loss = 0.4073\n",
            "Epoch 600: Loss = 0.3871\n",
            "Epoch 700: Loss = 0.3706\n",
            "Epoch 800: Loss = 0.3570\n",
            "Epoch 900: Loss = 0.3455\n",
            "Epoch 1000: Loss = 0.3358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    final_preds = model(inputs_tensor, w, b)\n",
        "    predicted_classes = final_preds.round().int()\n",
        "    true_classes = targets_tensor.int()\n",
        "\n",
        "    correct = (predicted_classes == true_classes).sum().item()\n",
        "    accuracy = correct / targets_tensor.size(0)\n",
        "\n",
        "    print(\"\\nФінальні передбачення:\")\n",
        "    print(final_preds)\n",
        "\n",
        "    print(f\"\\nТочність: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "KPiqz9mbg907",
        "outputId": "f71faf39-7602-4aa0-eef2-9b2abcf0ab2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Фінальні передбачення:\n",
            "tensor([[0.5777],\n",
            "        [0.6685],\n",
            "        [0.9113],\n",
            "        [0.1616],\n",
            "        [0.8653]])\n",
            "\n",
            "Точність: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ],
      "metadata": {
        "id": "fuRhlyF9qAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ],
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ],
      "metadata": {
        "id": "7X2dV30KtAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_tensor = torch.from_numpy(inputs)\n",
        "targets_tensor = torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "chrvMfBs6vjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(inputs_tensor, targets_tensor)"
      ],
      "metadata": {
        "id": "FNnbgJhWIsJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"Елемент {i}: Вхідні дані = {train_ds[i][0]}, Мітка = {train_ds[i][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN_ipwIRIvix",
        "outputId": "291ed89e-4d91-4707-fa15-776968411cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Елемент 0: Вхідні дані = tensor([73., 67., 43.]), Мітка = tensor([0.])\n",
            "Елемент 1: Вхідні дані = tensor([91., 88., 64.]), Мітка = tensor([1.])\n",
            "Елемент 2: Вхідні дані = tensor([ 87., 134.,  58.]), Мітка = tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ],
      "metadata": {
        "id": "4nMFaa8suOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=5, shuffle=True)"
      ],
      "metadata": {
        "id": "ZCsRo5Mx6wEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch = next(iter(train_dl))"
      ],
      "metadata": {
        "id": "FHLfTFQDJSMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_batch, targets_batch = first_batch\n",
        "print(\"Вхідні дані батчу:\\n\", inputs_batch)\n",
        "print(\"Мітки батчу:\\n\", targets_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE0dmWgJJUFS",
        "outputId": "015b9847-ced2-4225-a05e-daf43789ccf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вхідні дані батчу:\n",
            " tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [102.,  43.,  37.]])\n",
            "Мітки батчу:\n",
            " tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ],
      "metadata": {
        "id": "ymcQOo_hum6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogReg(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogReg, self).__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.act(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogReg()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wGIfTUtKFYz",
        "outputId": "a3b78845-e505-4965-a65e-894f1a9f5476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogReg(\n",
            "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ],
      "metadata": {
        "id": "RflV7xeVyoJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "3QCATPU_6yfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = F.binary_cross_entropy"
      ],
      "metadata": {
        "id": "0ZX7G3uYKn2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs_tensor)\n",
        "loss = loss_fn(preds, targets_tensor)\n",
        "\n",
        "print(\"Втрати (loss):\", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIOqARa8L0RV",
        "outputId": "9021f680-2118-400c-a75f-1e3a12b8b351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Втрати (loss): 7.631152629852295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Модель ще не навчилась — це видно з того, що значення втрат (loss) становить 7.63, що є надто високим для задачі бінарної класифікації. Це означає, що передбачення моделі поки що дуже далекі від правильних міток. Ймовірно, потрібно або збільшити learning rate, або провести кілька епох навчання, щоб модель почала краще пристосовуватись до даних.*"
      ],
      "metadata": {
        "id": "yinoRhyrPVpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ],
      "metadata": {
        "id": "ch-WrYnKzMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for xb, yb in train_dl:\n",
        "            pred = model(xb)\n",
        "\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    return losses"
      ],
      "metadata": {
        "id": "CrUeejGJKoYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = fit_return_loss(1000, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htx7m9PNLMAp",
        "outputId": "0535c732-bdea-4d6a-b321-c372b7b1d202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 4.5353\n",
            "Epoch [200/1000], Loss: 3.6974\n",
            "Epoch [300/1000], Loss: 2.8748\n",
            "Epoch [400/1000], Loss: 2.0854\n",
            "Epoch [500/1000], Loss: 1.3831\n",
            "Epoch [600/1000], Loss: 0.8436\n",
            "Epoch [700/1000], Loss: 0.5492\n",
            "Epoch [800/1000], Loss: 0.4263\n",
            "Epoch [900/1000], Loss: 0.3627\n",
            "Epoch [1000/1000], Loss: 0.3297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cEHQH9qE626k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "67ad186c-4e93-48db-9af8-e47d4a6cd53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs_tensor)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37UCS8qZNwF9",
        "outputId": "9037b36e-0df0-4b9b-eb91-3b3e927c0c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5729],\n",
              "        [0.6791],\n",
              "        [0.9026],\n",
              "        [0.1569],\n",
              "        [0.8761],\n",
              "        [0.5729],\n",
              "        [0.6791],\n",
              "        [0.9026],\n",
              "        [0.1569],\n",
              "        [0.8761],\n",
              "        [0.5729],\n",
              "        [0.6791],\n",
              "        [0.9026],\n",
              "        [0.1569],\n",
              "        [0.8761]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_int = (preds >= 0.5).int()\n",
        "print(preds_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dnY_p93OYX6",
        "outputId": "9b4989cf-4181-401e-e18f-be6d71999e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfWnxLDnN8id",
        "outputId": "b520986d-32e2-4b2a-adee-14552e9ea1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Маємо 12 правильних із 15"
      ],
      "metadata": {
        "id": "6bapGWfjOxQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets_tensor_int = torch.tensor(targets).squeeze().int()\n",
        "\n",
        "# Обчислення точності\n",
        "accuracy = (preds_int.squeeze() == targets_tensor_int).sum().item() / len(targets_tensor_int)\n",
        "print(f\"Точність моделі: {accuracy:.1%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJl8AlWKOCtA",
        "outputId": "cf57a5fb-da95-4592-f317-fee7b6e6feff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точність моделі: 80.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Після 1000 епох навчання модель логістичної регресії показала стабільне зменшення втрат — з початкових 7.63 до 0.33. Це свідчить про те, що модель поступово навчилась знаходити закономірності у вхідних даних. Графік також підтверджує хорошу динаміку навчання.\n",
        "\n",
        "У результаті передбачення стали досить точними — 80% правильних відповідей (12 з 15)."
      ],
      "metadata": {
        "id": "k1b1XbqZP-kU"
      }
    }
  ]
}